---
layout: default
title: ESWC 2017 paper experiment
materialicon: whatshot
---

<div class="container" id="index-banner">
	<h2 class="header center orange-text">Automated interconnection of Linked Data applications and datasets</h2>
    <h3 class="header center orange-text">Details of experiments for ESWC 2017 submission</h3>
	<div class="row">
		<p class="flow-text">This page provide details of the experiments presented in our ESWC 2017 submission.</p>
		<ol class="flow-text">
			<li><a href="#datasets">Datasets</a></li>
			<li><a href="#applications">Applications</a></li>
			<li><a href="#transformers">Transformers</a></li>
			<li><a href="#results">Experiment results</a></li>
			<li><a href="#prototype">Platform prototype overview</a></li>
			<li><a href="#reproducing">Reproducing the experimental results</a></li>
		</ol>
	</div>
	<div class="row">
		<h4 id="datasets">
			Datasets
		</h4>
		<p class="flow-text">We have chosen 16 real-world datasets and manually created their output data graphs. The output data graphs are necessary for the application pipeline disocvery algorithm to be able to include the datasets to discovered pipelines.</p>
		<p class="flow-text">They are presented in the following table. For each dataset, the table specifies:</p>
		<ul class="flow-text">
			<li><b>Datasource</b> - link to the datasource from which the dataset was extracted</li>
			<li><b>Dataset</b> - name of the dataset</li>
			<li><b>Dataset extraction query</b> - SPARQL query to extract the dataset from the datasource</li>
			<li><b>Output data graph</b> - output data graph of the datasource necessary for the application pipeline discovery algorithm</li>
		</ul>
		<table class="flow-text highlight">
			<thead>
				<tr><th>Datasource</th><th>Dataset</th><th>Dataset extraction query</th><th>Output data graph</th></tr>
			</thead>
			<tbody>
				<tr><td><a href="http://dblp.l3s.de/d2r/sparql">SPARQL endpoint</a></td><td>DBLP</td><td><a href="datasets/extractor-dblp.sparql">query</a></td><td><a href="datasets/graph-dblp.ttl">graph</a></td></tr>
				<tr><td><a href="http://dbpedia.org/sparql">SPARQL endpoint</a></td><td>DBPedia - Earthquakes</td><td><a href="datasets/extractor-dbpedia-earthquakes.sparql">query</a></td><td><a href="datasets/graph-dbpedia-earthquakes.ttl">graph</a></td></tr>
				<tr><td><a href="http://dbpedia.org/sparql">SPARQL endpoint</a></td><td>DBPedia - Towns</td><td><a href="datasets/extractor-towns.sparql">query</a></td><td><a href="datasets/graph-towns.ttl">graph</a></td></tr>
				<tr><td><a href="http://www.europeandataportal.eu/sparql">SPARQL endpoint</a></td><td>European Data Portal</td><td><a href="datasets/extractor-edp.sparql">query</a></td><td><a href="datasets/graph-edp.ttl">graph</a></td></tr>
				<tr><td><a href="http://linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>Check actions - Czech Supreme Audit Office</td><td><a href="datasets/extractor-checkactions-cz-sao.sparql">query</a></td><td><a href="datasets/graph-checkactions-cz-sao.ttl">graph</a></td></tr>
				<tr><td><a href="http://linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>Check actions - Czech Trade Inspection Authority</td><td><a href="datasets/extractor-checkactions-cz-ctia.sparql">query</a></td><td><a href="datasets/graph-checkactions-cz-ctia.ttl">graph</a></td></tr>
				<tr><td><a href="http://linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>Legislation CZ - Acts</td><td><a href="datasets/extractor-legislation-cz-acts.sparql">query</a></td><td><a href="datasets/graph-legislation-cz-acts.ttl">graph</a></td></tr>
				<tr><td><a href="http://linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>Legislation CZ - Versions of Acts</td><td><a href="datasets/extractor-legislation-cz-acts-versions.sparql">query</a></td><td><a href="datasets/graph-legislation-cz-acts-versions.ttl">graph</a></td></tr>
				<tr><td><a href="http://gov.tso.co.uk/legislation/sparql">SPARQL endpoint</a></td><td>Legislation UK - Acts</td><td><a href="datasets/extractor-legislation-gb-acts.sparql">query</a></td><td><a href="datasets/graph-legislation-gb-acts.ttl">graph</a></td></tr>
				<tr><td><a href="http://gov.tso.co.uk/legislation/sparql">SPARQL endpoint</a></td><td>Legislation UK - Versions of Acts</td><td><a href="datasets/extractor-legislation-gb-acts-versions.sparql">query</a></td><td><a href="datasets/graph-legislation-gb-acts-versions.ttl">graph</a></td></tr>
				<tr><td><a href="http://data.linkedmdb.org/sparql">SPARQL endpoint</a></td><td>LinkedMDB</td><td><a href="datasets/extractor-linkedmdb.sparql">query</a></td><td><a href="datasets/graph-linkedmdb.ttl">graph</a></td></tr>
				<tr><td><a href="http://ruian.linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>RÚIAN - Address Places in Czech Republic</td><td><a href="datasets/extractor-cz-ruian-address-places.sparql">query</a></td><td><a href="datasets/graph-cz-ruian-address-places.ttl">graph</a></td></tr>
				<tr><td><a href="http://ruian.linked.opendata.cz/sparql">SPARQL endpoint</a></td><td>RÚIAN - Towns in Czech Republic</td><td><a href="datasets/extractor-cz-ruian-towns.sparql">query</a></td><td><a href="datasets/graph-cz-ruian-towns.ttl">graph</a></td></tr>
				<tr><td><a href="http://cedropendata.mfcr.cz/c3lod/cedr/sparql">SPARQL endpoint</a></td><td>Subsidies from public budgets in Czech Republic</td><td><a href="datasets/extractor-subsidies-cz-cedr.sparql">query</a></td><td><a href="datasets/graph-subsidies-cz-cedr.ttl">graph</a></td></tr>
				<tr><td><a href="http://data.dcs.shef.ac.uk/dump/datadcs-withdblpV1-2Mar2010.rdf">RDF dump</a></td><td>University of Sheffield - Department of Comp. Sc.</td><td><a href="datasets/extractor-department-of-computer-science-university-of-sheffield.sparql">query</a></td><td><a href="datasets/graph-department-of-computer-science-university-of-sheffield.ttl">graph</a></td></tr>
				<tr><td><a href="http://query.wikidata.org">SPARQL endpoint</a></td><td>Towns in Wikidata</td><td><a href="datasets/extractor-wikidata-towns.sparql">query</a></td><td><a href="datasets/graph-wikidata-towns.ttl">graph</a></td></tr>
			</tbody>
		</table>
	</div>
	<div class="row">
		<h4 id="applications">
			Applications
		</h4>
	</div>
	<div class="row">
    	<p class="flow-text">
			TBA
		</p>
	</div>
	<div class="row">
		<h4 id="transformers">
			Transformers
		</h4>
	</div>
	<div class="row">
    	<p class="flow-text">
			TBA
		</p>
	</div>
	<div class="row">
		<h4 id="results">
			Experiment results
		</h4>
	</div>
	<div class="row">
    	<p class="flow-text">
			TBA
		</p>
	</div>
	<div class="row">
		<h4 id="prototype">
			Platform prototype overview
		</h4>
	</div>
	<div class="row">
    	<p class="flow-text">
			TBA
		</p>
	</div>
	<div class="row">
		<h4 id="reproducing">
			Reproducing the experimental results
		</h4>
	</div>
    <div class="row">
        <p class="flow-text">This page describes the steps necessary to reproduce the results described in our ESWC 2017 paper submission.</p>
    </div>
    <div class="row">
    	<p class="flow-text">
	    	To evaluate the proposed platform we have implemented LinkedPipes.
			LinkedPipes is a suite of web services, each specialized on different tasks related to processing LinkedData.
			In this chapter, we describe the current state of the implementation of this suite.
			We briefly describe the services related to application pipeline discovery.
			We also describe, how the services communicate with each other in order to support application pipeline discovery workflows.
		</p>  

		<p>
			The application pipeline discovery itself is implemented in the <em>discovery service</em>, which provides the following API:
		</p>  

		<pre>
		start   POST         /discovery/start
		status  GET          /discovery/$id
		list    GET          /discovery/$id/pipelines
		csv     GET          /discovery/$id/csv
		export  GET          /discovery/$id/pipelines/$pipelineId
		execute GET          /discovery/$id/pipelines/$pipelineId/execute
		stop    GET          /discovery/$id/stop
		</pre>

		<p>
			The discovery itself is executed by calling the <em>start</em> API call.
			This API call expects a discovery configuration JSON object to be posted:
		</p>

		<pre>
		{
		    "sparqlEndpoints": [{
		        "url": "http://www.europeandataportal.eu/sparql",
		        "descriptorIri": "https://...sample.ttl",
		        "defaultGraphIris": [],
		        "label": "European Data Portal"
		    }]
		}
		</pre>

		<p>
			The configuration object allows the user to specify an array of SPARQL endpoint definitions. For each endpoint, it requires its URL and dereferencable IRI of it's descriptor.
			Optionally, it accepts also list of default graph IRIs, which are named graphs that are to be considered while performing the discovery.
			In order to make the discovery results more readable, it also accepts a label that user can define to distinguish the endpoints.
		</p>

		<p>
			When the <em>start</em> API call is executed, it returns a JSON object containing just one property, which is an ID of the started pipeline discovery instance:
		</p>

		<pre>
		{ "id": "c1582982-1038-4218-911c-12c94ebd2b19" }
		</pre>

		<p>
		This ID is to be used later as a parameter of the remaining API calls.
		</p>

		<p>
			The next step is wait for the discovery to complete.
			Although the partial results (discovered application pipelines are available via the <em>list</em> API call immediately after the iteration in which a pipeline is discovered are found, the \emph{status} API call could be used to wait for the discovery to complete.
		</p>

		<pre>
		{
		  "pipelineCount": 1,
		  "isFinished": true,
		  "duration": 350
		}
		</pre>

		<p>	
			Once the <em>isFinished</em> property is set to <em>true</em>, the pipeline discovery is finished and we can call the <em>list</em> API call to obtain all discovered application pipelines.
			The returned data contain details about all the discovered pipelines, mainly which of the provided datasources were used, what application is able to consume data from them and what are the transformations needed to assemble the application pipeline.
			Moreover, it contains an ID assigned to every discovered pipeline.
		</p>	

		<p>	
			Such an ID can be later used with the <em>export</em> or <em>execute</em> API calls.
			The former responds with a JSON-LD data that are in a format consumed by our ETL service.
			The latter directly contacts a pre-configured ETL service instance, imports the specified pipeline into it and executes its processing.
		</p>

		<p>	
			There are two more API calls that we did not mention so far.
			One of them is the <em>stop</em> API call, which can be used to terminate the pipeline discovery if necessary.
			The last one is named <em>csv</em>, which is an API call that temporarily simulates the ranking service.
			We used it for conducting the experiments.
			It implements the aforementioned ranking logic and provides us with a quick overview of what are the results of the discovery.
		</p>
    </div>
        
</div>
